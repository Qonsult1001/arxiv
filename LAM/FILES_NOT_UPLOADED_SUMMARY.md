# Files Not Uploaded to GitHub

This document lists all files that were excluded from the GitHub push due to size limitations (>50MB per file).

**Total files excluded: 67**

## Summary by Category

### Model Files (.pt, .bin, .safetensors, .onnx, .h5, .ot)
- Base model files: 5 files
- Checkpoint files: 30+ files  
- ONNX model files: 5 files
- Other model formats: 3 files

### Large Data Files (.gz)
- reddit_title-body.jsonl.gz (813MB)
- yahoo_answers.jsonl.gz (126MB)
- stackexchange_title_body.jsonl.gz (118MB)

## Complete List of Excluded Files

1. LAM/LAM-base-v0.1/lam_base.bin
2. LAM/LAM-base-v0.1/lam_tweak.pt
3. LAM/LAM-base-v1/pytorch_model.bin
4. LAM/LAM_384_MRL_Trained.bin
5. LAM/all-MiniLM-L6-v2/model.safetensors
6. LAM/all-MiniLM-L6-v2/onnx/model.onnx
7. LAM/all-MiniLM-L6-v2/onnx/model_O1.onnx
8. LAM/all-MiniLM-L6-v2/onnx/model_O2.onnx
9. LAM/all-MiniLM-L6-v2/onnx/model_O3.onnx
10. LAM/all-MiniLM-L6-v2/openvino/openvino_model.bin
11. LAM/all-MiniLM-L6-v2/pytorch_model.bin
12. LAM/all-MiniLM-L6-v2/rust_model.ot
13. LAM/all-MiniLM-L6-v2/tf_model.h5
14. LAM/best/deltanet_shockwave_result.pt
15. LAM/best/pytorch_model.bin
16. LAM/best/pytorch_model.bin.backup
17. LAM/checkpoint_167000_converted.pt
18. LAM/data/reddit_title-body.jsonl.gz (813MB)
19. LAM/data/stackexchange_title_body.jsonl.gz (118MB)
20. LAM/data/yahoo_answers.jsonl.gz (126MB)
21. LAM/deltanet_limit_breaker.pt
22. LAM/deltanet_limit_breaker_1.pt
23. LAM/deltanet_limit_breaker_2.pt
24. LAM/deltanet_limit_breaker_3.pt
25. LAM/deltanet_limit_breaker_4.pt
26. LAM/deltanet_limit_breaker_5.pt
27. LAM/deltanet_limit_breaker_6.pt
28. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEW/checkpoint_52000.pt
29. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEW/pytorch_model.bin
30. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_104000.pt
31. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_105000.pt
32. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_106000.pt
33. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_107000.pt
34. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_108000.pt
35. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_109000.pt
36. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_110000.pt
37. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_111000.pt
38. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_112000.pt
39. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_113000.pt
40. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/checkpoint_114000.pt
41. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEW/pytorch_model.bin
42. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEWFINAL/checkpoint_167000.pt
43. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEWFINAL/checkpoint_190000.pt
44. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEWFINAL/final_model/pytorch_model.bin
45. LAM/deltanet_minilm_6layers_FIXED_FROM_SCRATCH_NEWNEWFINAL/pytorch_model.bin
46. LAM/deltanet_multitask_final_corrected.pt
47. LAM/deltanet_multitask_final_corrected_sick.pt
48. LAM/deltanet_roberta_tsl_distilled.pt
49. LAM/deltanet_shockwave_result.pt
50. LAM/deltanet_super_vector_best.pt
51. LAM/dual_pass_model.pt
52. LAM/publish/deltanet_roberta_tsl_distilled.pt
53. LAM/pure_constant_lr2/checkpoint_167000.pt
54. LAM/pure_constant_lr2/checkpoint_167001.pt
55. LAM/pure_constant_lr2/checkpoint_167002.pt
56. LAM/pure_constant_lr2/checkpoint_167003.pt
57. LAM/pure_constant_lr2/checkpoint_167004.pt
58. LAM/pure_constant_lr2/checkpoint_167005.pt
59. LAM/pure_constant_lr2/checkpoint_167006.pt
60. LAM/pure_constant_lr2/checkpoint_167007.pt
61. LAM/pure_constant_lr2/checkpoint_167008.pt
62. LAM/pure_constant_lr2/checkpoint_167009.pt
63. LAM/pure_constant_lr2/checkpoint_167010.pt
64. LAM/pure_constant_lr2/checkpoint_167011.pt
65. LAM/titan_model.pt
66. LAM/titan_trained/best_model.pt
67. LAM/titan_trained/checkpoint_5000.pt

## Note

These files remain in the local repository but were excluded from the push to avoid GitHub's size limitations. They can be uploaded separately using Git LFS or alternative storage solutions if needed.

